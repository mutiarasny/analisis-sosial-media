{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPzYL4ar/3KB8yASHmzzurl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mutiarasny/analisis-sosial-media/blob/main/crawling_data_twiiter_2000.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nH52tVvN_68D"
      },
      "outputs": [],
      "source": [
        "#@title Twitter Auth Token\n",
        "\n",
        "twitter_auth_token = '6c1240768ce85b62f306872e24' # change this auth token"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required Python package\n",
        "!pip install pandas\n",
        "\n",
        "# Install Node.js (because tweet-harvest built using Node.js)\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install -y ca-certificates curl gnupg\n",
        "!sudo mkdir -p /etc/apt/keyrings\n",
        "!curl -fsSL https://deb.nodesource.com/gpgkey/nodesource-repo.gpg.key | sudo gpg --dearmor -o /etc/apt/keyrings/nodesource.gpg\n",
        "\n",
        "!NODE_MAJOR=20 && echo \"deb [signed-by=/etc/apt/keyrings/nodesource.gpg] https://deb.nodesource.com/node_$NODE_MAJOR.x nodistro main\" | sudo tee /etc/apt/sources.list.d/nodesource.list\n",
        "\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install nodejs -y\n",
        "\n",
        "!node -v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJoOdYdhAO1T",
        "outputId": "52c257c6-a485-4883-90e3-3d4703d9717a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Ign:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Get:6 https://r2u.stat.illinois.edu/ubuntu jammy Release [5,713 B]\n",
            "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy Release.gpg [793 B]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,326 kB]\n",
            "Hit:13 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,150 kB]\n",
            "Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,582 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [3,181 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,308 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [3,097 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,440 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,585 kB]\n",
            "Fetched 24.9 MB in 3s (7,328 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ca-certificates is already the newest version (20230311ubuntu0.22.04.1).\n",
            "gnupg is already the newest version (2.2.27-3ubuntu2.1).\n",
            "gnupg set to manually installed.\n",
            "Suggested packages:\n",
            "  libcurl4-doc libidn11-dev libldap2-dev librtmp-dev\n",
            "The following packages will be upgraded:\n",
            "  curl libcurl4 libcurl4-openssl-dev\n",
            "3 upgraded, 0 newly installed, 0 to remove and 62 not upgraded.\n",
            "Need to get 869 kB of archives.\n",
            "After this operation, 3,072 B of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libcurl4-openssl-dev amd64 7.81.0-1ubuntu1.18 [386 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 curl amd64 7.81.0-1ubuntu1.18 [194 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libcurl4 amd64 7.81.0-1ubuntu1.18 [289 kB]\n",
            "Fetched 869 kB in 1s (653 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "(Reading database ... 123599 files and directories currently installed.)\n",
            "Preparing to unpack .../libcurl4-openssl-dev_7.81.0-1ubuntu1.18_amd64.deb ...\n",
            "Unpacking libcurl4-openssl-dev:amd64 (7.81.0-1ubuntu1.18) over (7.81.0-1ubuntu1.17) ...\n",
            "Preparing to unpack .../curl_7.81.0-1ubuntu1.18_amd64.deb ...\n",
            "Unpacking curl (7.81.0-1ubuntu1.18) over (7.81.0-1ubuntu1.17) ...\n",
            "Preparing to unpack .../libcurl4_7.81.0-1ubuntu1.18_amd64.deb ...\n",
            "Unpacking libcurl4:amd64 (7.81.0-1ubuntu1.18) over (7.81.0-1ubuntu1.17) ...\n",
            "Setting up libcurl4:amd64 (7.81.0-1ubuntu1.18) ...\n",
            "Setting up curl (7.81.0-1ubuntu1.18) ...\n",
            "Setting up libcurl4-openssl-dev:amd64 (7.81.0-1ubuntu1.18) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "deb [signed-by=/etc/apt/keyrings/nodesource.gpg] https://deb.nodesource.com/node_20.x nodistro main\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:3 https://deb.nodesource.com/node_20.x nodistro InRelease [12.1 kB]\n",
            "Hit:4 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Ign:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:7 https://r2u.stat.illinois.edu/ubuntu jammy Release\n",
            "Get:8 https://deb.nodesource.com/node_20.x nodistro/main amd64 Packages [8,901 B]\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:12 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:13 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:14 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Fetched 21.0 kB in 1s (15.6 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  nodejs\n",
            "0 upgraded, 1 newly installed, 0 to remove and 62 not upgraded.\n",
            "Need to get 31.7 MB of archives.\n",
            "After this operation, 197 MB of additional disk space will be used.\n",
            "Get:1 https://deb.nodesource.com/node_20.x nodistro/main amd64 nodejs amd64 20.17.0-1nodesource1 [31.7 MB]\n",
            "Fetched 31.7 MB in 1s (58.4 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package nodejs.\n",
            "(Reading database ... 123599 files and directories currently installed.)\n",
            "Preparing to unpack .../nodejs_20.17.0-1nodesource1_amd64.deb ...\n",
            "Unpacking nodejs (20.17.0-1nodesource1) ...\n",
            "Setting up nodejs (20.17.0-1nodesource1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "v20.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Crawl Data\n",
        "\n",
        "filename = 'azarine_Sep2223.csv'\n",
        "search_keyword = 'azarine since:2024-09-22 until:2024-09-17 lang:id'\n",
        "limit = 2000\n",
        "\n",
        "!npx -y tweet-harvest@2.6.1 -o \"{filename}\" -s \"{search_keyword}\" --tab \"LATEST\" -l {limit} --token {twitter_auth_token}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHpQh5bQATOW",
        "outputId": "cf7d4f5a-e6f7-471e-e9c0-94b2f72948e3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K\u001b[1m\u001b[32mTweet Harvest [v2.6.1]\u001b[39m\u001b[22m\n",
            "\u001b[1m\u001b[32m\u001b[39m\u001b[22m\n",
            "\u001b[34mResearch by \u001b[39m\u001b[1m\u001b[34mHelmi Satria\u001b[39m\u001b[22m\u001b[34m\u001b[39m\n",
            "\u001b[34mUse it for Educational Purposes only!\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[33mThis script uses Chromium Browser to crawl data from Twitter with \u001b[1myour Twitter auth token\u001b[22m.\u001b[39m\n",
            "\u001b[33mPlease enter your Twitter auth token when prompted.\u001b[39m\n",
            "\u001b[33m\u001b[39m\n",
            "\u001b[31m\u001b[1mNote:\u001b[22m\u001b[39m Keep your access token secret! Don't share it with anyone else.\n",
            "\u001b[31m\u001b[1mNote:\u001b[22m\u001b[39m This script only runs on your local device.\n",
            "\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mOpening twitter search page...\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[90m\u001b[39m\n",
            "\u001b[90m-- Scrolling... (1)\u001b[39m\u001b[90m (2)\u001b[39m\u001b[33m\u001b[39m\n",
            "\u001b[33mFilling in keywords: azarine since:2024-09-15 until:2024-09-17 lang:id\u001b[39m\n",
            "\u001b[33m\u001b[39m\n",
            "\u001b[90m (3)\u001b[39m\u001b[90m (4)\u001b[39m\u001b[34m\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/azarine_Sep1516.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 6\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/azarine_Sep1516.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 8\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/azarine_Sep1516.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 21\u001b[39m\n",
            "\u001b[90m\u001b[39m\n",
            "\u001b[90m-- Scrolling... (1)\u001b[39m\u001b[90m (2)\u001b[39m\u001b[90m (3)\u001b[39m\u001b[34m\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/azarine_Sep1516.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 40\u001b[39m\n",
            "\u001b[90m\u001b[39m\n",
            "\u001b[90m-- Scrolling... (1)\u001b[39m\u001b[34m\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/azarine_Sep1516.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 60\u001b[39m\n",
            "\u001b[90m\u001b[39m\n",
            "\u001b[90m-- Scrolling... (1)\u001b[39m\u001b[34m\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/azarine_Sep1516.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 78\u001b[39m\n",
            "\u001b[90m\u001b[39m\n",
            "\u001b[90m-- Scrolling... (1)\u001b[39m\u001b[34m\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/azarine_Sep1516.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 96\u001b[39m\n",
            "\u001b[90m\u001b[39m\n",
            "\u001b[90m-- Scrolling... (1)\u001b[39m\u001b[34m\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/azarine_Sep1516.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 113\u001b[39m\n",
            "\u001b[90m\u001b[39m\n",
            "\u001b[90m--Taking a break, waiting for 10 seconds...\u001b[39m\n",
            "\u001b[90m\u001b[39m\n",
            "\u001b[90m-- Scrolling... (1)\u001b[39m\u001b[34m\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/azarine_Sep1516.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 130\u001b[39m\n",
            "\u001b[90m\u001b[39m\n",
            "\u001b[90m-- Scrolling... (1)\u001b[39m\u001b[34m\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/azarine_Sep1516.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 149\u001b[39m\n",
            "\u001b[90m\u001b[39m\n",
            "\u001b[90m-- Scrolling... (1)\u001b[39m\u001b[34m\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/azarine_Sep1516.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 167\u001b[39m\n",
            "\u001b[90m\u001b[39m\n",
            "\u001b[90m-- Scrolling... (1)\u001b[39m\u001b[90m (2)\u001b[39m\u001b[90m (3)\u001b[39m\u001b[34m\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/azarine_Sep1516.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 185\u001b[39m\n",
            "\u001b[90m\u001b[39m\n",
            "\u001b[90m-- Scrolling... (1)\u001b[39m\u001b[34m\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/azarine_Sep1516.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 202\u001b[39m\n",
            "\u001b[90m\u001b[39m\n",
            "\u001b[90m-- Scrolling... (1)\u001b[39m\u001b[90m (2)\u001b[39m\u001b[90m (3)\u001b[39m\u001b[34m\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/azarine_Sep1516.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 220\u001b[39m\n",
            "\u001b[90m\u001b[39m\n",
            "\u001b[90m--Taking a break, waiting for 10 seconds...\u001b[39m\n",
            "\u001b[90m\u001b[39m\n",
            "\u001b[90m-- Scrolling... (1)\u001b[39m\u001b[31m\u001b[90m[v2.6.1]\u001b[39m No more tweets found, please check your search criteria and csv file result\u001b[39m\n",
            "\u001b[90m\u001b[39m\n",
            "\u001b[90m-- Scrolling... (1)\u001b[39m\u001b[90m (2)\u001b[39m\u001b[90m (3)\u001b[39m\u001b[90m (4)\u001b[39m\u001b[90m (5)\u001b[39m\u001b[90m (6)\u001b[39m\u001b[90m (7)\u001b[39m\u001b[90m (8)\u001b[39m\u001b[90m (9)\u001b[39m\u001b[90m (10)\u001b[39m\u001b[90m (11)\u001b[39m\u001b[90m (12)\u001b[39m\u001b[90m (13)\u001b[39m\u001b[90m (14)\u001b[39m\u001b[90m (15)\u001b[39m\u001b[90m (16)\u001b[39m\u001b[90m (17)\u001b[39m\u001b[90m (18)\u001b[39m\u001b[90m (19)\u001b[39m\u001b[90m (20)\u001b[39m\u001b[90m (21)\u001b[39m\u001b[33mNo more tweets found, please check your search criteria and csv file result\u001b[39m\n",
            "\u001b[33mTimeout reached 1 times, making sure again...\u001b[39m\n",
            "\u001b[31m\u001b[90m[v2.6.1]\u001b[39m No more tweets found, please check your search criteria and csv file result\u001b[39m\n",
            "\u001b[90m\u001b[39m\n",
            "\u001b[90m-- Scrolling... (1)\u001b[39m\u001b[90m (2)\u001b[39m\u001b[90m (3)\u001b[39m\u001b[90m (4)\u001b[39m\u001b[90m (5)\u001b[39m\u001b[90m (6)\u001b[39m\u001b[90m (7)\u001b[39m\u001b[90m (8)\u001b[39m\u001b[90m (9)\u001b[39m\u001b[90m (10)\u001b[39m\u001b[90m (11)\u001b[39m\u001b[90m (12)\u001b[39m\u001b[90m (13)\u001b[39m\u001b[90m (14)\u001b[39m\u001b[90m (15)\u001b[39m\u001b[90m (16)\u001b[39m\u001b[90m (17)\u001b[39m\u001b[90m (18)\u001b[39m\u001b[90m (19)\u001b[39m\u001b[90m (20)\u001b[39m\u001b[90m (21)\u001b[39m\u001b[33mNo more tweets found, please check your search criteria and csv file result\u001b[39m\n",
            "\u001b[33mTimeout reached 2 times, making sure again...\u001b[39m\n",
            "\u001b[90m\u001b[39m\n",
            "\u001b[90m-- Scrolling... (1)\u001b[39m\u001b[90m (2)\u001b[39m\u001b[90m (3)\u001b[39m\u001b[90m (4)\u001b[39m\u001b[90m (5)\u001b[39m\u001b[90m (6)\u001b[39m\u001b[90m (7)\u001b[39m\u001b[90m (8)\u001b[39m\u001b[90m (9)\u001b[39m\u001b[90m (10)\u001b[39m\u001b[90m (11)\u001b[39m\u001b[90m (12)\u001b[39m\u001b[90m (13)\u001b[39m\u001b[90m (14)\u001b[39m\u001b[90m (15)\u001b[39m\u001b[90m (16)\u001b[39m\u001b[90m (17)\u001b[39m\u001b[90m (18)\u001b[39m\u001b[90m (19)\u001b[39m\u001b[90m (20)\u001b[39m\u001b[90m (21)\u001b[39m\u001b[33mNo more tweets found, please check your search criteria and csv file result\u001b[39m\n",
            "\u001b[33mTimeout reached 3 times, making sure again...\u001b[39m\n",
            "\u001b[31m\u001b[90m[v2.6.1]\u001b[39m No more tweets found, please check your search criteria and csv file result\u001b[39m\n",
            "\u001b[90m\u001b[39m\n",
            "\u001b[90m-- Scrolling... (1)\u001b[39m\u001b[90m (2)\u001b[39m\u001b[90m (3)\u001b[39m\u001b[90m (4)\u001b[39m\u001b[90m (5)\u001b[39m\u001b[90m (6)\u001b[39m\u001b[90m (7)\u001b[39m\u001b[90m (8)\u001b[39m\u001b[90m (9)\u001b[39m\u001b[90m (10)\u001b[39m\u001b[90m (11)\u001b[39m\u001b[90m (12)\u001b[39m\u001b[90m (13)\u001b[39m\u001b[90m (14)\u001b[39m\u001b[90m (15)\u001b[39m\u001b[90m (16)\u001b[39m\u001b[90m (17)\u001b[39m\u001b[90m (18)\u001b[39m\u001b[90m (19)\u001b[39m\u001b[90m (20)\u001b[39mGot 220 tweets, done scrolling...\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Specify the path to your CSV file\n",
        "file_path = f\"tweets-data/{filename}\"\n",
        "\n",
        "# Read the CSV file into a pandas DataFrame\n",
        "df = pd.read_csv(file_path, delimiter=\",\")\n",
        "\n",
        "# Display the DataFrame\n",
        "display(df)"
      ],
      "metadata": {
        "id": "CjyVO6S3AqsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cek jumlah data yang didapatkan\n",
        "\n",
        "num_tweets = len(df)\n",
        "print(f\"Jumlah tweet dalam dataframe adalah {num_tweets}.\")"
      ],
      "metadata": {
        "id": "PhO8dGaJAwEt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}